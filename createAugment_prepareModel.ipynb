{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHOmgVK0IcfuqyqutKVn23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamChomicki/CNN/blob/main/createAugment_prepareModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrKcB6Eu16Gu"
      },
      "outputs": [],
      "source": [
        "class createAugment(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, X, y, batch_size=32, dim=(160, 160), n_channels=3, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Oznacza liczbę batchy na epokę'\n",
        "        return int(np.floor(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generuje jeden batch danych'\n",
        "        # Generuj indeksy batchy\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Generuj dane\n",
        "        return self.__data_generation(indexes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Aktualizuj indeksy po każdej epoce'\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, idxs):\n",
        "        # Masked_images jest macierzą zamaskowanych obrazów używanych jako dane wejściowe\n",
        "        Masked_images = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))  # Zamaskowany obraz\n",
        "        # Mask_batch jest macierzą masek binarnych używanych jako dane wejściowe\n",
        "        Mask_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))  # Maski binarne\n",
        "        # y_batch jest macierzą oryginalnych obrazów używanych do obliczania błędu z zrekonstruowanego obrazu\n",
        "        y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))  # Obraz oryginalny\n",
        "\n",
        "        ## Iteracja przez losowe indeksy\n",
        "        for i, idx in enumerate(idxs):\n",
        "            image_copy = self.X[idx].copy()\n",
        "\n",
        "            ## Pobierz maskę związaną z tym obrazem\n",
        "            masked_image, mask = self.__createMask(image_copy)\n",
        "\n",
        "            Masked_images[i,] = masked_image / 255\n",
        "            Mask_batch[i,] = mask / 255\n",
        "            y_batch[i] = self.y[idx] / 255\n",
        "\n",
        "        ## Return mask as well because partial convolution require the same.\n",
        "        return [Masked_images, Mask_batch], y_batch\n",
        "\n",
        "    def __createMask(self, img):\n",
        "        ## Przygotuj maskującą macierz\n",
        "        mask = np.full((*self.dim, 3), 255, np.uint8)  ## Białe tło\n",
        "        for _ in range(np.random.randint(1, 10)):\n",
        "            # Pobierz losowe lokalizacje x do linii startu\n",
        "            x1, x2 = np.random.randint(1, self.dim[0]), np.random.randint(1, self.dim[0])\n",
        "            # Pobierz losowe lokalizacje y do linii startu\n",
        "            y1, y2 = np.random.randint(1, self.dim[1]), np.random.randint(1, self.dim[1])\n",
        "            # Uzyskaj losową grubość rysowanej linii\n",
        "            thickness = np.random.randint(1, 3)\n",
        "            # Narysuj czarną linię na białej masce\n",
        "            cv2.line(mask, (x1, y1), (x2, y2), (0, 0, 0), thickness)\n",
        "\n",
        "        ## Maska zdjęcia\n",
        "        masked_image = img.copy()\n",
        "        masked_image[mask == 0] = 255\n",
        "\n",
        "        return masked_image, mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PConv2D(Conv2D):\n",
        "    def __init__(self, *args, n_channels=3, mono=False, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.input_spec = [InputSpec(ndim=4), InputSpec(ndim=4)]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "\n",
        "        if input_shape[0][channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
        "\n",
        "        self.input_dim = input_shape[0][channel_axis]\n",
        "\n",
        "        # Image kernel\n",
        "        kernel_shape = self.kernel_size + (self.input_dim, self.filters)\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='img_kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        # Mask kernel\n",
        "        self.kernel_mask = K.ones(shape=self.kernel_size + (self.input_dim, self.filters))\n",
        "\n",
        "        # Oblicz rozmiar wypełnienia, aby osiągnąć zero-padding\n",
        "        self.pconv_padding = (\n",
        "            (int((self.kernel_size[0] - 1) / 2), int((self.kernel_size[0] - 1) / 2)),\n",
        "            (int((self.kernel_size[0] - 1) / 2), int((self.kernel_size[0] - 1) / 2)),\n",
        "        )\n",
        "\n",
        "        # Rozmiar okna - używany do normalizacji\n",
        "        self.window_size = self.kernel_size[0] * self.kernel_size[1]\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        '''\n",
        "        Będziemy używać metody Keras conv2d, i zasadniczo musimy\n",
        "        pomnożenie maski przez dane wejściowe X, zanim zastosujemy\n",
        "        konwolucji. Dla samej maski zastosujemy konwolucje z wszystkimi wagami\n",
        "        ustawionymi na 1.\n",
        "        Następnie przycinamy wartości maski do wartości pomiędzy 0 a 1\n",
        "        '''\n",
        "\n",
        "        # Należy dostarczyć zarówno obraz jak i maskę\n",
        "        if type(inputs) is not list or len(inputs) != 2:\n",
        "            raise Exception(\n",
        "                'PartialConvolution2D must be called on a list of two tensors [img, mask]. Instead got: ' + str(inputs))\n",
        "\n",
        "        # Padding done explicitly so that padding becomes part of the masked partial convolution\n",
        "        images = K.spatial_2d_padding(inputs[0], self.pconv_padding, self.data_format)\n",
        "        masks = K.spatial_2d_padding(inputs[1], self.pconv_padding, self.data_format)\n",
        "\n",
        "        # Zastosuj konwolucje do maski\n",
        "        mask_output = K.conv2d(\n",
        "            masks, self.kernel_mask,\n",
        "            strides=self.strides,\n",
        "            padding='valid',\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate\n",
        "        )\n",
        "\n",
        "        # Zastosuj konwolucje do obrazu\n",
        "        img_output = K.conv2d(\n",
        "            (images * masks), self.kernel,\n",
        "            strides=self.strides,\n",
        "            padding='valid',\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate\n",
        "        )\n",
        "\n",
        "        # Obliczanie współczynnika maski dla każdego piksela w masce wyjściowej\n",
        "        mask_ratio = self.window_size / (mask_output + 1e-8)\n",
        "\n",
        "        # Wyjście klipu ma być pomiędzy 0 a 1\n",
        "        mask_output = K.clip(mask_output, 0, 1)\n",
        "\n",
        "        # Usuń wartości współczynników, w których występują otwory\n",
        "        mask_ratio = mask_ratio * mask_output\n",
        "\n",
        "        # Normalizacja obrazu wyjściowego\n",
        "        img_output = img_output * mask_ratio\n",
        "\n",
        "        # Zastosuj bias tylko do obrazu (jeśli został wybrany)\n",
        "        if self.use_bias:\n",
        "            img_output = K.bias_add(\n",
        "                img_output,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        # Zastosuj aktywacje na obrazie\n",
        "        if self.activation is not None:\n",
        "            img_output = self.activation(img_output)\n",
        "\n",
        "        return [img_output, mask_output]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            space = input_shape[0][1:-1]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding='same',\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            new_shape = (input_shape[0][0],) + tuple(new_space) + (self.filters,)\n",
        "            return [new_shape, new_shape]\n",
        "        if self.data_format == 'channels_first':\n",
        "            space = input_shape[2:]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding='same',\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            new_shape = (input_shape[0], self.filters) + tuple(new_space)\n",
        "            return [new_shape, new_shape]\n",
        "\n",
        "def conv_output_length(input_length, filter_size,\n",
        "                       padding, stride, dilation=1):\n",
        "    \"\"\"Określa długość wyjściową konwolucji dla danej długości wejściowej.\n",
        "    # Arguments\n",
        "        input_length: integer.\n",
        "        filter_size: integer.\n",
        "        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
        "        stride: integer.\n",
        "        dilation: dilation rate, integer.\n",
        "    # Returns\n",
        "        The output length (integer).\n",
        "    \"\"\"\n",
        "    if input_length is None:\n",
        "        return None\n",
        "    assert padding in {'same', 'valid', 'full', 'causal'}\n",
        "    dilated_filter_size = (filter_size - 1) * dilation + 1\n",
        "    if padding == 'same':\n",
        "        output_length = input_length\n",
        "    elif padding == 'valid':\n",
        "        output_length = input_length - dilated_filter_size + 1\n",
        "    elif padding == 'causal':\n",
        "        output_length = input_length\n",
        "    elif padding == 'full':\n",
        "        output_length = input_length + dilated_filter_size - 1\n",
        "    return (output_length + stride - 1) // stride"
      ],
      "metadata": {
        "id": "SQ_Jn9-A4hIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __encoder_layer(filters, in_layer, in_mask):\n",
        " conv1, mask1 = PConv2D(160, (3,3), strides=1, padding='same')([in_layer, in_mask])\n",
        " conv1 = keras.activations.relu(conv1)\n",
        "\n",
        " conv2, mask2 = PConv2D(160, (3,3), strides=2, padding='same')([conv1, mask1])\n",
        " conv2 = keras.layers.BatchNormalization()(conv2, training=True)\n",
        " conv2 = keras.activations.relu(conv2)\n",
        "\n",
        " return conv1, mask1, conv2, mask2"
      ],
      "metadata": {
        "id": "V_gFt2RJ41MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __decoder_layer( filter1, filter2, in_img, in_mask, share_img, share_mask):\n",
        " up_img = keras.layers.UpSampling2D(size=(2,2))(in_img)\n",
        " up_mask = keras.layers.UpSampling2D(size=(2,2))(in_mask)\n",
        " concat_img = keras.layers.Concatenate(axis=3)([share_img, up_img])\n",
        " concat_mask = keras.layers.Concatenate(axis=3)([share_mask, up_mask])\n",
        "\n",
        " conv1, mask1 = PConv2D(filter1, (3,3), padding='same')([concat_img, concat_mask])\n",
        " conv1 = keras.activations.relu(conv1)\n",
        "\n",
        " conv2, mask2 = PConv2D(filter2, (3,3), padding='same')([conv1, mask1])\n",
        " conv2 = keras.layers.BatchNormalization()(conv2)\n",
        " conv2 = keras.activations.relu(conv2)\n",
        "\n",
        " return conv1, mask1, conv2, mask2"
      ],
      "metadata": {
        "id": "vhIeUuZS41JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "   y_true_f = keras.backend.flatten(y_true)\n",
        "   y_pred_f = keras.backend.flatten(y_pred)\n",
        "   intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
        "   return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))"
      ],
      "metadata": {
        "id": "79190E-L41Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model(hp):\n",
        "    input_size = (160, 160, 3)\n",
        "    input_image = keras.layers.Input(input_size, name=\"input_1\")\n",
        "    input_mask = keras.layers.Input(input_size, name=\"input_2\")\n",
        "\n",
        "    n_filters = hp.Int('n_filters', min_value=32, max_value=256, step=32)\n",
        "    n_decoders = hp.Int('n_decoders', min_value=50, max_value=450, step=30)\n",
        "\n",
        "    conv1, mask1, conv2, mask2 = __encoder_layer(n_filters, input_image, input_mask)\n",
        "    conv3, mask3, conv4, mask4 = __encoder_layer(2 * n_filters, conv2, mask2)\n",
        "    conv5, mask5, conv6, mask6 = __encoder_layer(4 * n_filters, conv4, mask4)\n",
        "    conv7, mask7, conv8, mask8 = __encoder_layer(8 * n_filters, conv6, mask6)\n",
        "\n",
        "    conv9, mask9, conv10, mask10 = __decoder_layer(8 * n_filters, 4 * n_decoders, conv8, mask8, conv7, mask7)\n",
        "    conv11, mask11, conv12, mask12 = __decoder_layer(4 * n_filters, 2 * n_decoders, conv10, mask10, conv5, mask5)\n",
        "    conv13, mask13, conv14, mask14 = __decoder_layer(2 * n_filters, n_decoders, conv12, mask12, conv3, mask3)\n",
        "    conv15, mask15, conv16, mask16 = __decoder_layer(n_filters, 3, conv14, mask14, conv1, mask1)\n",
        "\n",
        "    outputs = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv16)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_image, input_mask], outputs=[outputs])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss=dice_coef)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "OzR3L1aN41DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcMrt6tH403Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}